{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce74ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25defc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILE = <FILL OUT FILE NAME HERE>\n",
    "df = pd.read_json(OUTFILE, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5959be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'bert-base-uncased'\n",
    "\n",
    "sciBert = transformers.BertModel.from_pretrained(MODEL)\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(MODEL, do_lower_case=True)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "sciBert = sciBert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca330d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f970a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE_EACH = len(df)\n",
    "\n",
    "def __embedding(text):\n",
    "    return compute_mean(embedding_fn(sciBert, text))\n",
    "\n",
    "def compute_bert_embeddings(dataframe_chunk, current_index, end_marker, filename):\n",
    "    np_chunk = __embedding(dataframe_chunk.loc[current_index * end_marker]['text']).detach().numpy()\n",
    "\n",
    "    for idx in range(1, end_marker):\n",
    "        try:\n",
    "            embedding = __embedding(dataframe_chunk.loc[(current_index * end_marker) + idx]['text']).detach().numpy()\n",
    "            np_chunk = np.append(np_chunk, embedding, axis = 0)\n",
    "            print('\\r {}'.format(np_chunk.shape), end = '')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            np_chunk = np.append(np_chunk, np.zeros(shape = (1, 768)), axis = 0)\n",
    "            continue \n",
    "\n",
    "    print(np_chunk.shape)\n",
    "    np.savez_compressed(filename.format(current_index), a = np_chunk)\n",
    "\n",
    "\n",
    "def compute_embeddings_and_save(dataframe, filename):\n",
    "    n_rows = len(dataframe)\n",
    "\n",
    "    chunk_sizes = n_rows // CHUNK_SIZE_EACH\n",
    "    remaining = n_rows - chunk_sizes * CHUNK_SIZE_EACH\n",
    "\n",
    "    for i in range(1):\n",
    "        compute_bert_embeddings(dataframe[i * CHUNK_SIZE_EACH : (i * CHUNK_SIZE_EACH) + CHUNK_SIZE_EACH ], i, \n",
    "                                CHUNK_SIZE_EACH,  filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6c99fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_fn(model, text) :\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer.encode(text, max_length=512)\n",
    "        batch_tokens = np.expand_dims(tokens, axis = 0)\n",
    "        batch_tokens = torch.tensor(batch_tokens).cuda()\n",
    "        batch_tokens = batch_tokens.to(device)\n",
    "        return model(batch_tokens)[0].cpu()\n",
    "\n",
    "def compute_mean(embedding):\n",
    "    if not isinstance(embedding, torch.Tensor):\n",
    "        print('Embedding must be a torch.Tensor')\n",
    "        return \n",
    "    return embedding.mean(1)\n",
    "\n",
    "def compute_cosine_measure(x1, x2):\n",
    "    return cosine_similarity(x1, x2)\n",
    "\n",
    "def compute_distance(x1, x2):\n",
    "    return compute_cosine_measure(x1.detach().numpy(), x2.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15d12668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mapping_index(dataframe):\n",
    "    index_map = {}\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        author_username = row['user']['screen_name']\n",
    "        author_userid = row['user']['id']\n",
    "        \n",
    "        index_map[index] = {\n",
    "            \"cord_uid\" : row['id'],\n",
    "            \"author_user_name\" : author_username,\n",
    "            \"text\" : row['text'],\n",
    "            \"author_userid\": author_userid\n",
    "        }\n",
    "\n",
    "    return index_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4ee3cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (101453, 768)(101453, 768)\n"
     ]
    }
   ],
   "source": [
    "compute_embeddings_and_save(df, <FILL EMBEDDING OUTFILENAME>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15cdbfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32638284"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_map = generate_mapping_index(df_trimmed)\n",
    "open(<FILL MAPPING OUTFILE NAME>, 'w').write(json.dumps(index_map))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
