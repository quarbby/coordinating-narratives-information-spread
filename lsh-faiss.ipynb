{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df212c76-b131-4d51-bfef-32d1fe497259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a30866d-cfd6-4c1a-9c3f-12720dc3274e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ajc.com/politics/kemp-condemns-pro...</td>\n",
       "      <td>Credit: WSBTV Videos Credit: WSBTV Videos Gov...</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://uscouriertoday.com/ken-starr-pulls-bac...</td>\n",
       "      <td>exception occurred with html parsing</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.thegatewaypundit.com/2021/01/pro-t...</td>\n",
       "      <td>Advertisement Police have been using a very h...</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.thegatewaypundit.com/2021/01/fulto...</td>\n",
       "      <td>Advertisement  The Georgia twin senate runoff...</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pscp.tv/w/csSSPDFsWktweXJveHB2am58...</td>\n",
       "      <td>unable to extract meaningful text</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.ajc.com/politics/kemp-condemns-pro...   \n",
       "1  https://uscouriertoday.com/ken-starr-pulls-bac...   \n",
       "2  https://www.thegatewaypundit.com/2021/01/pro-t...   \n",
       "3  https://www.thegatewaypundit.com/2021/01/fulto...   \n",
       "4  https://www.pscp.tv/w/csSSPDFsWktweXJveHB2am58...   \n",
       "\n",
       "                                                text   source  \n",
       "0   Credit: WSBTV Videos Credit: WSBTV Videos Gov...  website  \n",
       "1               exception occurred with html parsing  website  \n",
       "2   Advertisement Police have been using a very h...  website  \n",
       "3   Advertisement  The Georgia twin senate runoff...  website  \n",
       "4                  unable to extract meaningful text  website  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('./data/twitter_parler_text_url_data_pkl4.pkl')\n",
    "df['source'] = 'website'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea0ae887-6ae6-4a74-b62c-a9f9b21ea497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ajc.com/politics/kemp-condemns-pro...</td>\n",
       "      <td>Credit: WSBTV Videos Credit: WSBTV Videos Gov...</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.thegatewaypundit.com/2021/01/pro-t...</td>\n",
       "      <td>Advertisement Police have been using a very h...</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.thegatewaypundit.com/2021/01/fulto...</td>\n",
       "      <td>Advertisement  The Georgia twin senate runoff...</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.zerohedge.com/geopolitical/chinas-...</td>\n",
       "      <td>Authored by Doug Dodge via AmericanThinker.co...</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.thegatewaypundit.com/2021/01/ignor...</td>\n",
       "      <td>Advertisement  In late November we reported v...</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.ajc.com/politics/kemp-condemns-pro...   \n",
       "2  https://www.thegatewaypundit.com/2021/01/pro-t...   \n",
       "3  https://www.thegatewaypundit.com/2021/01/fulto...   \n",
       "5  https://www.zerohedge.com/geopolitical/chinas-...   \n",
       "6  https://www.thegatewaypundit.com/2021/01/ignor...   \n",
       "\n",
       "                                                text   source  \n",
       "0   Credit: WSBTV Videos Credit: WSBTV Videos Gov...  website  \n",
       "2   Advertisement Police have been using a very h...  website  \n",
       "3   Advertisement  The Georgia twin senate runoff...  website  \n",
       "5   Authored by Doug Dodge via AmericanThinker.co...  website  \n",
       "6   Advertisement  In late November we reported v...  website  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df['text'] != 'exception occurred with html parsing']\n",
    "df_filtered = df_filtered[df_filtered['text'] != 'unable to extract meaningful text']\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4deb8478-aea8-48b2-b0e7-f6600fc02ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "word_list = ['Advertisement']\n",
    "stop_words.extend(word_list)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if text == '' or text == None:\n",
    "        return ''\n",
    "    \n",
    "    text_cleaned = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "    text_cleaned = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text_cleaned)\n",
    "    text_cleaned = ' '.join([w for w in text_cleaned.split() if not w.lower() in stop_words])\n",
    "    text_cleaned = text_cleaned.replace('\\\"', '')\n",
    "    text_cleaned = text_cleaned.replace('\\'', '')\n",
    "    text_cleaned = text_cleaned.strip()\n",
    "    \n",
    "    return text_cleaned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8503d532-3d92-4ba4-8172-24186f71b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['text_processed'] = df_filtered['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082db984-2701-4323-86ab-723f3923ed46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96cca9d4-03d2-4006-883b-46eef04a2339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b890f4e4c14c49a2be1ce36bf21b1b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_list = {}\n",
    "\n",
    "for idx, row in tqdm(df_filtered.iterrows()):\n",
    "    text = row['text_processed']\n",
    "    text = text[:1000000] if len(text) > 1000000 else text\n",
    "    doc_list[idx] = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1196ea9-8ebf-41d2-a54b-89bd76639c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 300\n",
    "hyperplanes = 20 # to find out by PCA\n",
    "plane_norms = np.random.rand(hyperplanes, dimensions) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "796bf13a-e416-4d73-adb8-d96bd2247507",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map = {}\n",
    "index = faiss.IndexLSH(hyperplanes, hyperplanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebf79efe-5391-4c9e-97e3-b8e67165cce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plane_norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd0518fc-9634-4c4b-ae84-5d6e19bc8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(vec_reshape.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "111557ad-cdb5-4520-b5e7-988f57f84bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c950221d9f4a43b1ba1313f3768d28f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k,v in tqdm(doc_list.items()):\n",
    "    vec = v.vector\n",
    "    vec_dot = np.dot(vec, plane_norms.T)\n",
    "    vec_bin = vec_dot.astype(int)\n",
    "#     print(vec_bin.shape)\n",
    "    vec_reshape = vec_bin.reshape(1, hyperplanes).astype('float32')\n",
    "#     print(vec_reshape.shape)\n",
    "    \n",
    "    text = v.text\n",
    "    index_map[k] = {'text': text, 'vector': vec_reshape}\n",
    "    index.add(vec_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973af61-e0f3-4800-be76-e6e565a7c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open('./data/text_sim.csv', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da16ff3c-4209-4b13-9ff5-10577c06d437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d1248ea6f048efab8252d28edb174a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity_array = []\n",
    "\n",
    "for num in tqdm(range(0, len(doc_list))):\n",
    "    vec = doc_list[num].vector\n",
    "    vec_dot = np.dot(vec, plane_norms.T)\n",
    "    vec_reshape = vec_dot.reshape(1, 20).astype('float32')\n",
    "    \n",
    "    D, I = index.search(vec_reshape, k=5)\n",
    "    indices = I[0]\n",
    "    distances = D[0]\n",
    "    \n",
    "    for idx in range(0, len(indices)):\n",
    "        if indices[idx] != -1 and idx != num: \n",
    "            arr_obj = {}\n",
    "            arr_obj['orig_text'] = doc_list[num].text\n",
    "            arr_obj['matched_text'] = index_map[i]['text']\n",
    "            arr_obj['distance'] = distances[idx]\n",
    "            \n",
    "            similarity_array.append(arr_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bda30794-1c2f-4146-9ead-c0ec3d0d071d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_text</th>\n",
       "      <th>matched_text</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks contacting us received submission DAs c...</td>\n",
       "      <td>Technology Many President Donald Trump support...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thanks contacting us received submission DAs c...</td>\n",
       "      <td>Technology Many President Donald Trump support...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks contacting us received submission DAs c...</td>\n",
       "      <td>Technology Many President Donald Trump support...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thanks contacting us received submission DAs c...</td>\n",
       "      <td>Technology Many President Donald Trump support...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monday 11 January 2021 05 30 PM Facebook inten...</td>\n",
       "      <td>Technology Many President Donald Trump support...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           orig_text  \\\n",
       "0  Thanks contacting us received submission DAs c...   \n",
       "1  Thanks contacting us received submission DAs c...   \n",
       "2  Thanks contacting us received submission DAs c...   \n",
       "3  Thanks contacting us received submission DAs c...   \n",
       "4  Monday 11 January 2021 05 30 PM Facebook inten...   \n",
       "\n",
       "                                        matched_text  distance  \n",
       "0  Technology Many President Donald Trump support...       3.0  \n",
       "1  Technology Many President Donald Trump support...       3.0  \n",
       "2  Technology Many President Donald Trump support...       3.0  \n",
       "3  Technology Many President Donald Trump support...       3.0  \n",
       "4  Technology Many President Donald Trump support...       2.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sim = pd.DataFrame(similarity_array)\n",
    "df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e2b548c-29f3-425d-9166-3b96a5bfa07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.to_csv('./data/website_sim_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf93ed7-fc73-4706-a43a-f3961a1510ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SEARCH CODE \n",
    "num = 2\n",
    "vec = doc_list[num].vector\n",
    "vec_dot = np.dot(vec, plane_norms.T)\n",
    "vec_reshape = vec_dot.reshape(1, 20).astype('float32')\n",
    "D, I = index.search(vec_reshape, k=2)\n",
    "indices = I[0]\n",
    "distances = D[0]\n",
    "\n",
    "print(doc_list[num].text, '\\n\\n')\n",
    "\n",
    "for idx in range(0, len(indices)):\n",
    "    if indices[idx] != -1:\n",
    "        print(index_map[i]['text'], distances[idx], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
