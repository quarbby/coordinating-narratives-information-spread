{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a937024b-9192-4599-bc30-8963febffc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a3e5416-c115-41ac-a863-a91b5e01d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'bert-base-uncased'\n",
    "\n",
    "sciBert = transformers.BertModel.from_pretrained(MODEL)\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(MODEL, do_lower_case=True)\n",
    "device = \"cuda:0\"\n",
    "sciBert = sciBert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34010bf4-c31c-48f6-9b01-292748d379d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILENAME = \n",
    "OUTPUT_AUTHORS_FILENAME = \n",
    "OUTPUT_TEXT_FILENAME = \n",
    "INDEX_MAP_FILENAME = \n",
    "TWEET_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "711ae4cd-25ff-4863-9a9e-02d1e0ca988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_coord_authors_fh = open(OUTPUT_AUTHORS_FILENAME, 'w')\n",
    "text_coord_text_fh = open(OUTPUT_TEXT_FILENAME, 'w')\n",
    "\n",
    "text_coord_authors_fh.write('author1,author2,author1id,author2id,distance\\n')\n",
    "text_coord_text_fh.write('text1,text2,author1,author2,author1id,author2id,distance\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acea3839-ca1c-4d6d-babc-81bff2ab0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_fn(model, text) :\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer.encode(text, max_length=512)\n",
    "        batch_tokens = np.expand_dims(tokens, axis = 0)\n",
    "        batch_tokens = torch.tensor(batch_tokens).cuda()\n",
    "        batch_tokens = batch_tokens.to(device)\n",
    "        return model(batch_tokens)[0].cpu()\n",
    "\n",
    "def compute_mean(embedding):\n",
    "    if not isinstance(embedding, torch.Tensor):\n",
    "        print('Embedding must be a torch.Tensor')\n",
    "        return \n",
    "    return embedding.mean(1)\n",
    "\n",
    "def compute_cosine_measure(x1, x2):\n",
    "    return cosine_similarity(x1, x2)\n",
    "\n",
    "def compute_distance(x1, x2):\n",
    "    return compute_cosine_measure(x1.detach().numpy(), x2.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3aa1b9ca-0d6e-4608-98a8-9d9b6b862574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_title_t(indexes, distances, curr_author):\n",
    "    for i, idx in enumerate(indexes) :\n",
    "                \n",
    "        if index_map[str(idx)]['cord_uid'] == curr_author['idx']: \n",
    "            continue\n",
    "        distance = distances[i]\n",
    "        \n",
    "        matched_text = index_map[str(idx)]['text']\n",
    "        matched_author_name = index_map[str(idx)]['author_user_name']\n",
    "        matched_author_id = index_map[str(idx)]['author_userid']\n",
    "\n",
    "        matched_json = {}\n",
    "        matched_json['author1'] = curr_author['author_user_name']\n",
    "        matched_json['author2'] = matched_author_name\n",
    "\n",
    "        matched_json['author1id'] = curr_author['author_userid']\n",
    "        matched_json['author2id'] = matched_author_id\n",
    "\n",
    "        matched_json['text1idx'] = str(curr_author['idx'])\n",
    "        matched_json['text2idx'] = str(index_map[str(idx)]['cord_uid'])\n",
    "        matched_json['text1'] = curr_author['text']\n",
    "        matched_json['text2'] = matched_text\n",
    "        matched_json['distance'] = str(distance)\n",
    "        \n",
    "        text_coord_authors_fh.write(curr_author['author_user_name'] + ',' + matched_author_name + ',' + \n",
    "                                    str(curr_author['author_userid']) + ',' + str(matched_author_id) + ',' +\n",
    "                                    str(distance) + '\\n')\n",
    "\n",
    "        \n",
    "        text_coord_text_fh.write(curr_author['text'] + ',' + matched_text + ',' +\n",
    "                                 curr_author['author_user_name'] + ',' + matched_author_name + ',' + \n",
    "                                 str(curr_author['author_userid']) + ',' + str(matched_author_id) + ',' +\n",
    "                                 str(distance) + '\\n'\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd26cba-4946-4ecd-bb2b-cab5cf5c35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(EMBEDDING_FILENAME)['a']\n",
    "\n",
    "embeddings_32 = embeddings.astype('float32')\n",
    "n_dimensions = embeddings_32.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c2e98b-6a14-4592-a203-975b6b434f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastIndex_gpu = faiss.index_factory(n_dimensions, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "res = faiss.StandardGpuResources()\n",
    "fastIndex_gpu = faiss.index_cpu_to_gpu(res, 0, fastIndex_gpu)\n",
    "faiss.normalize_L2(embeddings_32)\n",
    "fastIndex_gpu.add(embeddings_32) \n",
    "n_embeddings = embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a39847-1ebf-4db7-a8a5-9f9bb97d81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(TWEET__FILENAME, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344ae24c-bb6c-4bd9-bb57-ed5393ac9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INDEX_MAP_FILENAME, 'r') as f:\n",
    "    index_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b1c2336-5842-4c96-b939-b7ced0fc1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "\n",
    "for i in range(0, n_embeddings):\n",
    "    emb = embeddings[i]\n",
    "    emb = emb.astype('float32').reshape(1,-1)\n",
    "    faiss.normalize_L2(emb)\n",
    "    \n",
    "    row = df.iloc[i]\n",
    "    curr_author = {}\n",
    "    curr_author['text'] = row['text']\n",
    "    curr_author['author_user_name'] = row['user']['screen_name']\n",
    "    curr_author['author_userid'] = row['user']['id']\n",
    "    curr_author['idx'] = row['id']\n",
    "    \n",
    "    distances, neighbors = fastIndex_gpu.search(emb, k)\n",
    "    index_to_title_t(neighbors[0], distances[0], curr_author)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
